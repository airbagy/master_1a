---
title: "STA 3431 Assignment #1"
author: "Yihan Duan"
date: "21/09/2021"
output: pdf_document
---

## Question 1

In this question, we choose another set of parameters for LCG. As discussed in
class, by the Hullâ€“Dobell Theorem, we want to make sure:

1. gcd(b, m) = 1
2. every "prime or 4" divisor of m also divides a - 1.

```{R tidy=TRUE}
# define random function
m = 2^32; a = 4 * 69069 + 1; b = 23606797 * 7 
latestval = 12345
nextrand = function() {
  latestval <<- (a*latestval+b) %% m
  return (latestval/m)
}

# record 100000 random variables
rand_vals = c(1000000)
for (i in 1:1000000) {
  rand_vals[i] = nextrand()
}
```

As we choose m to be 2^32, we only need b to be odd and a - 1 to be a multiple
of 4. To avoid similarities between Un and Un-1, we choose a relatively large a.

Let's see the statistics compared to theoretical values of Uniform(0, 1).

```{R}
# compare statistics with theoretical values
limits= c(100, 1000, 10000, 100000)
for (lmt in limits) {
  cat("For the first ", lmt, "observations:\n")
  cat("Real mean: ", mean(rand_vals[1:lmt]), ", should be: ", 0.5, '\n')
  cat("Real standard deviation: ", sd(rand_vals[1:lmt]), ", should be: ", sqrt(1/12), '\n')
}
```

### Randomness



```{R}
```

### Uniformity

Let's see the distribution of the numbers generated by this algorithm.

```{R tidy=TRUE}
# plot frequency of the first N variables.
par(mfrow=c(2,2))
for (lmt in limits) {
  hist(rand_vals[1:lmt], 
       main=paste("First ", lmt, " data points"), 
       xlab="value")
}
```

From the histograms alone, we can see that, as the number of observations
increases, the values are evenly (uniformly) distributed between 0 and 1. To
quantify this, we perform a Chi squared test 

## Question 2

As discussed in class, we can simulate exponential distribution and normal 
distribution using uniform distribution.

```{R}
# simulation size
n = 1000

# function for acquiring n Uniform random numbers
get_randvals <- function(n) {
  rand_vals = c(n)
  for (i in 1:n) {
    rand_vals[i] = nextrand()
  }
  return(rand_vals)
}

# function for estimating required expectation
get_exp <- function() {
  # lambda = 3
  U1 = get_randvals(n)
  Y= -log(U1) / 3
  
  # use Box-Muller transformation
  U2 = get_randvals(n)
  U3 = get_randvals(n)
  Z = sqrt(2 * log(1/U2)) * cos(2 * 3.14159265 * U3)
  
  # get vars
  X = abs((Y^2) * (Z^5) * sin((Y^3) * (Z^2)))
  
  # compute and output the mean and standard error
  m = mean(X)
  se = sd(X) / sqrt(n)
  cat("MC:  ", m, " +- ", se, "  (n=", n, ")", "\n", sep='')
  cat("  95% C.I.:  (", m-1.96*se, ",", m+1.96*se, ")\n", sep='')
}

n = 1000000
get_exp()
get_exp()
get_exp()
```

We can see that the variance is still pretty high. Try increasing the simulation
size to see if it gets better.

```{R}
# Incrase n to reduce standard error
n = 10000000
get_exp()
get_exp()
get_exp()
```

The estimated expectation value is 0.83 with the approximate 95% confidence interval being
about (0.82, 0.84). This estimation is not very accurate because:

1. the estimated standard error is relatively high (~ 0.0036). 
2. the result of "classical" Monte Carlo method still fluctuates a lot between 
different runs.

This is because the term $|Y^2Z^5|$ has high variance when 
$Y$ ~ $\text{Exponential}(3)$ and $Z$ ~ $\text{Normal}(0,1)$.


## Question 3

My student number is 1003118547. Using the last 4 digits, we have:
$$ A = 8, B = 5, C = 4, D = 7 $$

Then the function is defined by:

$$
g(x_1, x_2, x_3, x_4, x_5) = x_1^{14} 2^{x_2 + 3} (1 + \cos[x_1 + 2x_2 + 3x_3 + 4x_4 + 8x_5]) e^{-8x_4^2}e^{-9(x_4-3x_5)^2} \prod_{i=1}^{5}1_{0<x_i<1}
$$

We can compute the expected value by:

$$
I = \frac{\sum (h(x_i)g(x_i)/f(x_i))}{\sum (g(x_i)/f(x_i))}
$$




